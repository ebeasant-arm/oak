#!/usr/bin/env bash
# shellcheck disable=SC2034  # Unused variables OK as this script is `source`d.

set -o errexit
set -o nounset
set -o xtrace
set -o pipefail

# Set the default Rust log level to info if unset.
# https://docs.rs/env_logger
export RUST_LOG="${RUST_LOG:-info}"

# See https://pantheon.corp.google.com/gcr/images/oak-ci/GLOBAL/oak
# Select the correct Dockerfile for the underlying arch.
# Note that these can all be overridden from the environment as desired.
# Docker's target types align wih Go, and not with bash/linux, hence the
# hard coded transposition implicit here (i.e. aarch64->arm64v8)
if [[ "${MACHTYPE}" == "x86_64"* ]]; then
  # x86_64 is the default for Oak.
  readonly DOCKER_ARCH="${DOCKER_ARCH:-""}"
  readonly DOCKER_ARCH_PREFIX=""
  readonly DOCKER_ARCH_SUFFIX=""
else
  if [[ "${MACHTYPE}" == "aarch64"* ]] || [[ "${MACHTYPE}" == "arm64"* ]]; then
    # aarch64 requires transposition to Docker arch types:
    readonly DOCKER_ARCH="${DOCKER_ARCH:-"arm64v8"}"
  else
  # This will use the full target triple under Linux, or just the Arch
  # under Macos, due to the differnt expansions of $MACHTYPE under bash.
    readonly DOCKER_ARCH="${DOCKER_ARCH:-${MACHTYPE}}"
fi
  # Construct the Dockerfile prefix and the image suffixes.
  # We use := here, as above we can set the PREFIX/SUFFIX to empty.
  readonly DOCKER_ARCH_PREFIX="${DOCKER_ARCH_PREFIX:="${DOCKER_ARCH}."}"
  readonly DOCKER_ARCH_SUFFIX="${DOCKER_ARCH_SUFFIX:="-${DOCKER_ARCH}"}"
fi

# Default to the Google Cloud servers, Note the trailing slash.
# Override DOCKER_REPO with "" to perform a local build
readonly DOCKER_REPO="${DOCKER_REPO:-"gcr.io/oak-ci/"}"
readonly DOCKER_FILE="${DOCKER_FILE:-"${DOCKER_ARCH_PREFIX}Dockerfile"}"
readonly DOCKER_IMAGE_NAME="${DOCKER_IMAGE_NAME:-"${DOCKER_REPO}oak${DOCKER_ARCH_SUFFIX}"}"
readonly SERVER_DOCKER_IMAGE_NAME="${SERVER_DOCKER_IMAGE_NAME:-"${DOCKER_REPO}oak-server${DOCKER_ARCH_SUFFIX}"}"

readonly CACHE_DIR='bazel-cache'
readonly SERVER_BIN_DIR="${PWD}/oak_loader/bin"

# List all workspaces and stand-alone crates.
declare -ar ALL_CRATES=(
  examples
  experimental
  oak_abi
  oak_client
  oak_derive
  oak_functions/loader
  oak_io
  oak_loader
  oak_runtime
  oak_services
  oak_sign
  oak_utils
  runner
  sdk
)

# To set up remote cache write credentials:
# - navigate to https://pantheon.corp.google.com/iam-admin/serviceaccounts?project=oak-ci
# - click on "Create Service Account"
#   + use your @google.com username as the service account name (e.g. "tzn")
#   + leave the service account ID as is (e.g. "tzn-110")
#   + leave the service account description empty
# - grant the "Storage Object Admin" role to the newly created account
# - click on "Create Key", then select "JSON"
# - save the generated key as the file referenced below, within the project directory
#   + make sure to not check it in to git, check your `.gitignore` configuration
readonly OAK_REMOTE_CACHE_KEY='./.oak_remote_cache_key.json'

(
  # Disable xtrace to avoid leaking secrets in logs.
  set +o xtrace;
  # Do we have a JSON key for the remote cache.
  # https://docs.bazel.build/versions/master/remote-caching.html#google-cloud-storage
  if [[ ! -f "$OAK_REMOTE_CACHE_KEY" ]]; then
    # Check if this exists in the environment and it is not empty.
    if [[ -n "${BAZEL_GOOGLE_CREDENTIALS:-}" ]]; then
      echo "$BAZEL_GOOGLE_CREDENTIALS" > "$OAK_REMOTE_CACHE_KEY"
    fi
  fi
)

declare -a bazel_build_flags

# Use the remote cache, assuming it is publicly readable.
# See https://pantheon.corp.google.com/storage/browser/oak-bazel-cache?project=oak-ci
bazel_build_flags+=(
  '--remote_cache=https://storage.googleapis.com/oak-bazel-cache'
  # Fail immediately if the Bazel server lock cannot be acquired so that we can notice this in CI
  # and avoid attempting to parallelize steps that are actually serialized by Bazel.
  '--block_for_lock=false'
  # Useful to determine how long individual steps are taking in CI.
  '--show_timestamps'
)

# If we now have a key file, use it, otherwise disable uploading artifacts to remote cache.
# Note that this is only needed to write to the cache, not to read from it.
if [[ -f "$OAK_REMOTE_CACHE_KEY" ]]; then
  bazel_build_flags+=(
    "--google_credentials=$OAK_REMOTE_CACHE_KEY"
  )
else
  bazel_build_flags+=(
    '--remote_upload_local_results=false'
  )
fi

declare -a cargo_build_flags

cargo_build_flags+=(
  '--release'
)

if [[ "${OSTYPE}" == "darwin"*  ]]; then
  bazel_build_flags+=( '--config=darwin' )
else
  # The -linux-musl target is the officially supported way of producing fully
  # static binaries from a Rust program.  However, musl is explicitly built
  # on the Linux syscalll layer, and so is not available on macOS.
  cargo_build_flags+=(
    "--target=$MACHTYPE-unknown-linux-musl"
  )
fi

# Choose the correct Rust host target.
# Note that $MACHTYPE and $HOSTTYPE behave differently between darwin and
# linux.
if [[ "${OSTYPE}" == "darwin"*  ]]; then
  readonly RUST_HOST_TARGET="${RUST_HOST_TARGET:-$MACHTYPE-apple-darwin}"
else
  readonly RUST_HOST_TARGET="${RUST_HOST_TARGET:-$HOSTTYPE-unknown-linux-gnu}"
fi

# kill_pid tries to kill the given pid(s), first softly then more aggressively.
kill_pid() {
  local pids=( "$@" )
  echo "Killing ${pids[*]}"
  set +e
  local count=0
  while kill -INT "${pids[@]}" > /dev/null 2>&1; do
    sleep 1
    ((count++))
    still_alive=()
    for pid in "${pids[@]}"; do
      if ps -p "${pid}" > /dev/null ; then
        still_alive+=("${pid}")
      fi
    done
    if [[ ${#still_alive[@]} -eq 0 ]]; then
      break
    fi
    if [[ $count -gt 5 ]]; then
      echo "Now do kill -KILL ${still_alive[*]}"
      kill -KILL "${still_alive[@]}"
      break
    fi
    pids=("${still_alive[@]}")
    echo "Retry kill -INT ${pids[*]}"
  done
  set -e
}

declare -a to_kill

# kill_bg_pids will clean up any pids in ${to_kill}.
kill_bg_pids() {
  if [[ -n ${to_kill+x} ]]; then
    kill_pid "${to_kill[@]}"
    to_kill=()
  fi
}

trap kill_bg_pids EXIT
